{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38332bit4db10a2e16a4431a99420108f7e4013a",
   "display_name": "Python 3.8.3 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. From HTML\n",
    "\n",
    "*Using only beautiful soap*\n",
    "\n",
    "Save in a dataframe the next information using web scraping. Each row of the dataframe must have in different columns:\n",
    "\n",
    "- The name of the title\n",
    "- The id of the div where is the value scraped. If there is not id, then the value is must be numpy.nan\n",
    "- The name of the tag where is the value scraped.\n",
    "- The next scraped values in different rows: \n",
    "    - The value: \"Este es el segundo párrafo\"  --> Row 1\n",
    "    - The url https://pagina1.xyz/ --> Row 2\n",
    "    - The url https://pagina4.xyz/ --> Row 3\n",
    "    - The url https://pagina5.xyz/ --> Row 4\n",
    "    - The value \"links footer-links\" --> Row 5\n",
    "    - The value \"Este párrafo está en el footer\" --> Row 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Página de prueba</title>\n",
    "</head>\n",
    "<body>\n",
    "<div id=\"main\" class=\"full-width\">\n",
    "    <h1>El título de la página</h1>\n",
    "    <p>Este es el primer párrafo</p>\n",
    "    <p>Este es el segundo párrafo</p>\n",
    "    <div id=\"innerDiv\">\n",
    "        <div class=\"links\">\n",
    "            <a href=\"https://pagina1.xyz/\">Enlace 1</a>\n",
    "            <a href=\"https://pagina2.xyz/\">Enlace 2</a>\n",
    "        </div>\n",
    "        <div class=\"right\">\n",
    "            <div class=\"links\">\n",
    "                <a href=\"https://pagina3.xyz/\">Enlace 3</a>\n",
    "                <a href=\"https://pagina4.xyz/\">Enlace 4</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div id=\"footer\">\n",
    "        <!-- El footer -->\n",
    "        <p>Este párrafo está en el footer</p>\n",
    "        <div class=\"links footer-links\">\n",
    "            <a href=\"https://pagina5.xyz/\">Enlace 5</a>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sopa = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Página de prueba'"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "titulo= sopa.find(\"title\").get_text()\n",
    "titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Página de prueba'"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sopa.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<div class=\"full-width\" id=\"main\">\n<h1>El título de la página</h1>\n<p>Este es el primer párrafo</p>\n<p>Este es el segundo párrafo</p>\n<div id=\"innerDiv\">\n<div class=\"links\">\n<a href=\"https://pagina1.xyz/\">Enlace 1</a>\n<a href=\"https://pagina2.xyz/\">Enlace 2</a>\n</div>\n<div class=\"right\">\n<div class=\"links\">\n<a href=\"https://pagina3.xyz/\">Enlace 3</a>\n<a href=\"https://pagina4.xyz/\">Enlace 4</a>\n</div>\n</div>\n</div>\n<div id=\"footer\">\n<!-- El footer -->\n<p>Este párrafo está en el footer</p>\n<div class=\"links footer-links\">\n<a href=\"https://pagina5.xyz/\">Enlace 5</a>\n</div>\n</div>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "sopa.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'main'"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "sopa.div[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<a href=\"https://pagina1.xyz/\">Enlace 1</a>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "sopa.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<p>Este es el primer párrafo</p>,\n <p>Este es el segundo párrafo</p>,\n <p>Este párrafo está en el footer</p>]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pes=sopa.find_all('p')\n",
    "pes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Este es el primer párrafo',\n 'Este es el segundo párrafo',\n 'Este párrafo está en el footer']"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "pestring=[]\n",
    "for p in pes:\n",
    "    pst=p.get_text()\n",
    "    pestring.append(pst)\n",
    "pestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Este es el primer párrafo'"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "p_= sopa.find(\"p\").get_text()\n",
    "p_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<a href=\"https://pagina1.xyz/\">Enlace 1</a>,\n <a href=\"https://pagina2.xyz/\">Enlace 2</a>,\n <a href=\"https://pagina3.xyz/\">Enlace 3</a>,\n <a href=\"https://pagina4.xyz/\">Enlace 4</a>,\n <a href=\"https://pagina5.xyz/\">Enlace 5</a>]"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "links = sopa.find_all(\"a\")\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['https://pagina1.xyz/',\n 'https://pagina2.xyz/',\n 'https://pagina3.xyz/',\n 'https://pagina4.xyz/',\n 'https://pagina5.xyz/']"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "linkstr=[]\n",
    "for l in links:\n",
    "    h=l.get(\"href\")\n",
    "    linkstr.append(h)\n",
    "linkstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "ids = sopa.find_all(\"id\")\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'html' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-be02da6f54fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"\\w+\"'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id=.*\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'html' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import bs4\n",
    "\n",
    "soup = bs4.BeautifulSoup(html)\n",
    "\n",
    "x = [re.search('\"\\w+\"', e).group()[1:-1] for e in re.findall(\"id=.*\",str(soup.contents[0]))]\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<html lang=\"es\">\n<head>\n<meta charset=\"utf-8\"/>\n<title>Página de prueba</title>\n</head>\n<body>\n<div class=\"full-width\" id=\"main\">\n<h1>El título de la página</h1>\n<p>Este es el primer párrafo</p>\n<p>Este es el segundo párrafo</p>\n<div id=\"innerDiv\">\n<div class=\"links\">\n<a href=\"https://pagina1.xyz/\">Enlace 1</a>\n<a href=\"https://pagina2.xyz/\">Enlace 2</a>\n</div>\n<div class=\"right\">\n<div class=\"links\">\n<a href=\"https://pagina3.xyz/\">Enlace 3</a>\n<a href=\"https://pagina4.xyz/\">Enlace 4</a>\n</div>\n</div>\n</div>\n<div id=\"footer\">\n<!-- El footer -->\n<p>Este párrafo está en el footer</p>\n<div class=\"links footer-links\">\n<a href=\"https://pagina5.xyz/\">Enlace 5</a>\n</div>\n</div>\n</div>\n</body>\n</html>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "sopa.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "bs4.element.Tag"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "type(soup.contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['id=\"main\">', 'id=\"innerDiv\">', 'id=\"footer\">']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "lista = re.findall(\"id=.*\",str(soup.contents[0]))\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "main\ninnerDiv\nfooter\n"
    }
   ],
   "source": [
    "for e in lista:\n",
    "    print(re.search('\"\\w+\"', e).group()[1:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. From Amazon\n",
    "\n",
    "*Using  beautiful soap and/or regex*\n",
    "\n",
    "Save in a dataframe the next information using web scraping. Using product pages from Amazon, do the following: \n",
    "\n",
    "- Get the product name from the web and save it in a column called \"item_name\"\n",
    "- Get the price from the web and save it in a column called \"item_price\"\n",
    "\n",
    "While you are doing the exercise, document the steps you are doing. Try to do the program for generic pages. If you cannot do it generic, explain the reasons. \n",
    "\n",
    "-------------------------------\n",
    "\n",
    "**Example:** \n",
    "\n",
    "url = https://www.amazon.es/Tommy-Hilfiger-UM0UM00054-Camiseta-Hombre/dp/B01MYD0T1F/ref=sr_1_1?dchild=1&pf_rd_p=58224bec-cac9-4dd2-a42a-61b1db609c2d&pf_rd_r=VZQ1JTQXFVRZ9E9VSKX4&qid=1595364419&s=apparel&sr=1-1\n",
    "\n",
    "*item_name* --> \"Tommy Hilfiger Logo Camiseta de Cuello Redondo,Perfecta para El Tiempo Libre para Hombre\"\n",
    "\n",
    "*item_price* --> [[18,99 € - 46,59 €]] or one of the options.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting lxml\n  Downloading lxml-4.5.2-cp38-cp38-win32.whl (3.2 MB)\nInstalling collected packages: lxml\nSuccessfully installed lxml-4.5.2\n"
    }
   ],
   "source": [
    "!pip3 install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "item_name         item_price\n0  Tommy Hilfiger Logo Camiseta de Cuello Redondo...  18,99 € - 46,53 €\n"
    }
   ],
   "source": [
    "headers = {\n",
    "    \"User-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36\"}\n",
    "\n",
    "URL = 'https://www.amazon.es/Tommy-Hilfiger-UM0UM00054-Camiseta-Hombre/dp/B01MYD0T1F/ref=sr_1_1?dchild=1&pf_rd_p=58224bec-cac9-4dd2-a42a-61b1db609c2d&pf_rd_r=VZQ1JTQXFVRZ9E9VSKX4&qid=1595364419&s=apparel&sr=1-1'\n",
    "\n",
    "def amazon():\n",
    "\n",
    "    page = requests.get(URL, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "\n",
    "    item_name=[]\n",
    "    item_price=[]\n",
    "\n",
    "\n",
    "    item_name.append(soup.find(id=\"productTitle\").get_text(strip=True))\n",
    "    price=soup.find(id=\"priceblock_ourprice\").get_text()\n",
    "    price=unicodedata.normalize(\"NFKD\", price)\n",
    "    item_price.append(price)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({'item_name' : item_name,'item_price' : item_price})\n",
    "\n",
    "\n",
    "    print(df)\n",
    "\n",
    "amazon()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "search() missing 1 required positional argument: 'string'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d93aad3b86f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mitem_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"productTitle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"priceblock.price\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municodedata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NFKD\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mitem_price\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: search() missing 1 required positional argument: 'string'"
     ]
    }
   ],
   "source": [
    "# Dentro de la función sólo muestra el df con print. Fuera de ella lo muestra \"bonito\"\n",
    "\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(page.content, features=\"lxml\")\n",
    "\n",
    "item_name=[]\n",
    "item_price=[]\n",
    "\n",
    "\n",
    "item_name.append(soup.find(id=\"productTitle\").get_text(strip=True))\n",
    "price=soup.find(id=re.search(\"priceblock.price\")).get_text()\n",
    "price=unicodedata.normalize(\"NFKD\", price)\n",
    "item_price.append(price)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'item_name' : item_name,'item_price' : item_price})\n",
    "re.match()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = re.findall(\"id=.*\",str(soup.contents[0]))\n",
    "\n",
    "price=soup.find(id=\"priceblock_ourprice\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serviría para todas los productos que usen como atributo \"priceblock_ourprice\". No valdría para las ofertas del día, que tienen como atributo \"priceblock_dealprice\"."
   ]
  }
 ]
}